{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hardiashrestha/Team-19-aizenberGAARRS-/blob/main/U-net%20model%20for%20segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vDfu3TZqKneH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "514d30c9-8070-435f-bf61-767c53c4b37a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_TensorSliceDataset element_spec=TensorSpec(shape=(192, 256, 1), dtype=tf.float32, name=None)>\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import os\n",
        "\n",
        "image_paths = os.listdir('/content/drive/MyDrive/PH2 Dataset images')\n",
        "\n",
        "mask_paths = os.listdir('/content/drive/MyDrive/PH2 Dataset images')\n",
        "# print(mask_paths)\n",
        "maskp = []\n",
        "imgp = []\n",
        "for path in mask_paths:\n",
        "  maskp.append(f'/content/drive/MyDrive/PH2 Dataset images/{path}/{path}_lesion/{path}_lesion.bmp')\n",
        "mask_paths = maskp\n",
        "for path in image_paths:\n",
        "  imgp.append(f'/content/drive/MyDrive/PH2 Dataset images/{path}/{path}_Dermoscopic_Image/{path}.bmp')\n",
        "image_paths = imgp\n",
        "# Image size\n",
        "img_height, img_width = 192, 256\n",
        "\n",
        "# Function to preprocess images\n",
        "def preprocess_image(image):\n",
        "    image = img_to_array(image)\n",
        "    image = tf.image.resize(image, [img_height, img_width])\n",
        "    image = image / 255.0  # Normalize pixel values\n",
        "    return image\n",
        "\n",
        "# Function to preprocess masks\n",
        "def preprocess_mask(mask):\n",
        "    mask = img_to_array(mask)\n",
        "    mask = tf.image.resize(mask, [img_height, img_width])\n",
        "\n",
        "    mask = tf.cast(mask > 0.5, tf.float32)  # Convert to binary mask\n",
        "    mask = tf.image.rgb_to_grayscale(mask)\n",
        "    return mask\n",
        "\n",
        "# Load and preprocess images\n",
        "\n",
        "images = [preprocess_image(load_img(path)) for path in image_paths]\n",
        "\n",
        "# Load and preprocess masks\n",
        "\n",
        "masks = [preprocess_mask(load_img(path)) for path in mask_paths]\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "image_dataset = tf.data.Dataset.from_tensor_slices(images)\n",
        "mask_dataset = tf.data.Dataset.from_tensor_slices(masks)\n",
        "\n",
        "print(mask_dataset)\n",
        "# Combine images and masks\n",
        "dataset = tf.data.Dataset.zip((image_dataset, mask_dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw9e4wNjalDm",
        "outputId": "f073bf7e-7d3a-4f3c-f4c8-d3cd7175f6b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 192, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)          (None, 192, 256, 64)         1792      ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_36 (Ba  (None, 192, 256, 64)         256       ['conv2d_38[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)          (None, 192, 256, 64)         36928     ['batch_normalization_36[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_37 (Ba  (None, 192, 256, 64)         256       ['conv2d_39[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPoolin  (None, 96, 128, 64)          0         ['batch_normalization_37[0][0]\n",
            " g2D)                                                               ']                            \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)          (None, 96, 128, 128)         73856     ['max_pooling2d_8[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_38 (Ba  (None, 96, 128, 128)         512       ['conv2d_40[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)          (None, 96, 128, 128)         147584    ['batch_normalization_38[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_39 (Ba  (None, 96, 128, 128)         512       ['conv2d_41[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPoolin  (None, 48, 64, 128)          0         ['batch_normalization_39[0][0]\n",
            " g2D)                                                               ']                            \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)          (None, 48, 64, 256)          295168    ['max_pooling2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_40 (Ba  (None, 48, 64, 256)          1024      ['conv2d_42[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)          (None, 48, 64, 256)          590080    ['batch_normalization_40[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (Ba  (None, 48, 64, 256)          1024      ['conv2d_43[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooli  (None, 24, 32, 256)          0         ['batch_normalization_41[0][0]\n",
            " ng2D)                                                              ']                            \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)          (None, 24, 32, 512)          1180160   ['max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_42 (Ba  (None, 24, 32, 512)          2048      ['conv2d_44[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)          (None, 24, 32, 512)          2359808   ['batch_normalization_42[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_43 (Ba  (None, 24, 32, 512)          2048      ['conv2d_45[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooli  (None, 12, 16, 512)          0         ['batch_normalization_43[0][0]\n",
            " ng2D)                                                              ']                            \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)          (None, 12, 16, 1024)         4719616   ['max_pooling2d_11[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_44 (Ba  (None, 12, 16, 1024)         4096      ['conv2d_46[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)          (None, 12, 16, 1024)         9438208   ['batch_normalization_44[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_45 (Ba  (None, 12, 16, 1024)         4096      ['conv2d_47[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_8 (UpSamplin  (None, 24, 32, 1024)         0         ['batch_normalization_45[0][0]\n",
            " g2D)                                                               ']                            \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate  (None, 24, 32, 1536)         0         ['up_sampling2d_8[0][0]',     \n",
            " )                                                                   'batch_normalization_43[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)          (None, 24, 32, 512)          7078400   ['concatenate_8[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_46 (Ba  (None, 24, 32, 512)          2048      ['conv2d_48[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)          (None, 24, 32, 512)          2359808   ['batch_normalization_46[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (Ba  (None, 24, 32, 512)          2048      ['conv2d_49[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_9 (UpSamplin  (None, 48, 64, 512)          0         ['batch_normalization_47[0][0]\n",
            " g2D)                                                               ']                            \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate  (None, 48, 64, 768)          0         ['up_sampling2d_9[0][0]',     \n",
            " )                                                                   'batch_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)          (None, 48, 64, 256)          1769728   ['concatenate_9[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_48 (Ba  (None, 48, 64, 256)          1024      ['conv2d_50[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)          (None, 48, 64, 256)          590080    ['batch_normalization_48[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_49 (Ba  (None, 48, 64, 256)          1024      ['conv2d_51[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_10 (UpSampli  (None, 96, 128, 256)         0         ['batch_normalization_49[0][0]\n",
            " ng2D)                                                              ']                            \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenat  (None, 96, 128, 384)         0         ['up_sampling2d_10[0][0]',    \n",
            " e)                                                                  'batch_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)          (None, 96, 128, 128)         442496    ['concatenate_10[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_50 (Ba  (None, 96, 128, 128)         512       ['conv2d_52[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)          (None, 96, 128, 128)         147584    ['batch_normalization_50[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_51 (Ba  (None, 96, 128, 128)         512       ['conv2d_53[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_11 (UpSampli  (None, 192, 256, 128)        0         ['batch_normalization_51[0][0]\n",
            " ng2D)                                                              ']                            \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenat  (None, 192, 256, 192)        0         ['up_sampling2d_11[0][0]',    \n",
            " e)                                                                  'batch_normalization_37[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)          (None, 192, 256, 64)         110656    ['concatenate_11[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_52 (Ba  (None, 192, 256, 64)         256       ['conv2d_54[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)          (None, 192, 256, 64)         36928     ['batch_normalization_52[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_53 (Ba  (None, 192, 256, 64)         256       ['conv2d_55[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)          (None, 192, 256, 1)          65        ['batch_normalization_53[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31402497 (119.79 MB)\n",
            "Trainable params: 31390721 (119.75 MB)\n",
            "Non-trainable params: 11776 (46.00 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 1685s 243s/step - loss: 0.5027 - accuracy: 0.5487 - val_loss: 768.9071 - val_accuracy: 3.3569e-06\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1633s 238s/step - loss: 0.3506 - accuracy: 0.6104 - val_loss: 4372.0181 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1623s 237s/step - loss: 0.3092 - accuracy: 0.6509 - val_loss: 9934.0088 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "4/7 [================>.............] - ETA: 7:34 - loss: 0.3486 - accuracy: 0.5973"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import *\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "\n",
        "def unet_model(input_size=(192, 256, 3)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "\n",
        "    # Decoder\n",
        "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=-1)\n",
        "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = BatchNormalization()(conv6)\n",
        "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n",
        "    conv6 = BatchNormalization()(conv6)\n",
        "\n",
        "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=-1)\n",
        "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = BatchNormalization()(conv7)\n",
        "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
        "    conv7 = BatchNormalization()(conv7)\n",
        "\n",
        "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=-1)\n",
        "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(up8)\n",
        "    conv8 = BatchNormalization()(conv8)\n",
        "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
        "    conv8 = BatchNormalization()(conv8)\n",
        "\n",
        "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=-1)\n",
        "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(up9)\n",
        "    conv9 = BatchNormalization()(conv9)\n",
        "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n",
        "    conv9 = BatchNormalization()(conv9)\n",
        "\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[inputs], outputs=[conv10])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = unet_model()\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "# dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)\n",
        "# # Split the dataset into training and testing sets\n",
        "# train_dataset = dataset['train']\n",
        "# test_dataset = dataset['test']\n",
        "\n",
        "# Define preprocessing function\n",
        "# def preprocess_data(example):\n",
        "#     image = tf.image.resize(example['image'], (256, 256)) / 255.0  # Resize and normalize images\n",
        "#     mask = tf.image.resize(example['segmentation_mask'], (256, 256))  # Resize masks\n",
        "#     mask = tf.cast(mask > 0, tf.float32)  # Take only the first channel (binary mask)\n",
        "#     return image, mask\n",
        "\n",
        "# from ph2 import dataset\n",
        "# Apply preprocessing to the datasets\n",
        "train_dataset = dataset\n",
        "val_dataset = dataset\n",
        "\n",
        "\n",
        "# Batch and shuffle the datasets\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).shuffle(buffer_size=1000)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "# print(train_dataset)\n",
        "\n",
        "# Define and compile the model\n",
        "model = unet_model(input_size=(192, 256, 3))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_dataset, epochs=10, validation_data=val_dataset)\n",
        "\n",
        "# # Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(val_dataset)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "\n",
        "# # Plot training history\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "model.saveweights('U-net Model')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "17BpuUZWu_drZDWtS2pojdPoJFgm6hK69",
      "authorship_tag": "ABX9TyNGteAEnKhLo4IWueghFq/k",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}